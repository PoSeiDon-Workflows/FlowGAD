{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398a1e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check that MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e49cb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Example of graph classification problem \"\"\"\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.nn import global_mean_pool as gap\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "from torch.nn import Linear, ModuleList, ReLU, Tanh, Sequential\n",
    "import torch.nn.functional as F\n",
    "import os.path as osp\n",
    "import sys\n",
    "sys.path.append('/Users/krishnanraghavan/Documents/Projects/Poseidon/graph_nn_2')\n",
    "\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "from psd_gnn.dataset import Merge_PSD_Dataset, PSD_Dataset\n",
    "# from psd_gnn.models.graph_classifier import GNN\n",
    "from psd_gnn.utils import process_args\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, f1_score,\n",
    "                             precision_score, recall_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric.loader import DataLoader, ImbalancedSampler, NeighborLoader\n",
    "from torch.distributions import LogNormal\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27a3b93a",
   "metadata": {},
   "source": [
    "The model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800b98af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_node_features: int,\n",
    "                 n_hidden: int,\n",
    "                 n_output: int,\n",
    "                 n_conv_blocks: int = 1 ) -> None:\n",
    "        \"\"\" Init the GNN model (new version).\n",
    "\n",
    "        Args:\n",
    "            n_node_features (int): Number of features at node level.\n",
    "            n_edge_features (int): Number of features at edge level.\n",
    "            n_hidden (int): Number of hidden dimension.\n",
    "            n_output (int): number of output dimension\n",
    "            n_conv_blocks (int): Number of\n",
    "        \"\"\"\n",
    "        # super class the class structure\n",
    "        super().__init__()\n",
    "\n",
    "        # add the ability to add one or more conv layers\n",
    "        conv_blocks = []\n",
    "\n",
    "        # ability to  add one or more conv blocks\n",
    "        for _ in range(n_conv_blocks):\n",
    "            conv_blocks += [\n",
    "                SAGEConv(n_node_features, n_hidden),\n",
    "                Tanh(),\n",
    "                SAGEConv(n_hidden, n_hidden),\n",
    "                Tanh(),\n",
    "            ]\n",
    "\n",
    "        # group all the conv layers\n",
    "        self.conv_layers = ModuleList(conv_blocks)\n",
    "\n",
    "        ## Summary statistics\n",
    "        self.summary_statistics = Sequential(\n",
    "            Linear(n_hidden, n_hidden),\n",
    "            Tanh(),\n",
    "            Linear(n_hidden, 2))\n",
    "        \n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def forward(self,\n",
    "                x: torch.Tensor,\n",
    "                edge_index: torch.Tensor,\n",
    "                batch: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Processing the GNN model.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input features at node level.\n",
    "            edge_index (torch.Tensor): Index pairs of vertices\n",
    "        Returns:\n",
    "            torch.Tensor: output tensor.\n",
    "        \"\"\"\n",
    "        for layer in self.conv_layers:\n",
    "            if isinstance(layer, SAGEConv) or isinstance(layer, GCNConv):\n",
    "                x = layer(x, edge_index)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        x = gap(x, batch)\n",
    "        pi   = self.summary_statistics(x)\n",
    "        return F.softmax(pi,dim=1)\n",
    "    \n",
    "\n",
    "\n",
    "    def loss_func(self, out, y):\n",
    "        out=out.to(DEVICE)\n",
    "        loss_cross_entropy = self.loss(out, y)\n",
    "        # dist=Categorical(out)\n",
    "        # action=dist.sample().numpy()[0] #take a sample from the categorical dist from 1-22\n",
    "        # print(action)\n",
    "        # loss_extreme= torch.mean(-1*torch.log(action))\n",
    "        \n",
    "        # sample = (self.dist.log_prob(self.dist.sample_n(32).squeeze(1)).exp() ).to(DEVICE)\n",
    "        # out=torch.sigmoid(out).to(DEVICE)\n",
    "        # loss_extreme = torch.mean(out-sample- torch.mul(out,\\\n",
    "        #                torch.log( out/(sample+1e-10) ) ) )\n",
    "        return (loss_cross_entropy)\n",
    "\n",
    "\n",
    "def train(model, loader):\n",
    "    \"\"\" Train function\n",
    "\n",
    "    Args:\n",
    "        model (object): GNN model instance.\n",
    "        loader (pyg.loader.DataLoader): Data loader object.\n",
    "\n",
    "    Returns:\n",
    "        float: Training accuracy.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    out_ret = []\n",
    "    for data in loader:\n",
    "        data = data.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = model.loss_func(out.float(), data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss.cpu().detach()) * data.num_graphs\n",
    "        out_ret+= out.squeeze(1).cpu().detach().numpy().tolist()\n",
    "    return total_loss / len(loader.dataset), out_ret, model\n",
    "\n",
    "\n",
    "\n",
    "import sklearn\n",
    "@torch.no_grad()\n",
    "def test(model, loader):\n",
    "    \"\"\" Evaluation function.\n",
    "\n",
    "    Args:\n",
    "        model (object): GNN model instance.\n",
    "        loader (pyg.loader.DataLoader): Data loader object.\n",
    "\n",
    "    Returns:\n",
    "        tuple (float, list): Testing accuracy, predicted labels.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    y_pred = []\n",
    "    outs = []\n",
    "    y_true = []\n",
    "    for data in loader:\n",
    "        data = data.to(DEVICE)\n",
    "        _, pred = torch.max(model(data.x, data.edge_index, data.batch), 1)\n",
    "        y_pred += pred.detach().cpu().numpy().tolist()\n",
    "        y_true += data.y.detach().cpu().numpy().tolist()\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_pred, y_true)\n",
    "    return accuracy, y_pred, y_true, outs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95e1f964",
   "metadata": {},
   "source": [
    "## The upper limits for each workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "664863b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all:   1%|          | 1/100 [00:01<01:54,  1.16s/it, train_loss=0.609, train_acc=0.792, val_acc=0.796]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1]), array([6149])) real (array([0, 1]), array([1270, 4879]))\n",
      "graph level clf: all binary True test acc 0.7935 f1 0.8848 recall 1.0000 prec 0.7935 [[   0 1270]\n",
      " [   0 4879]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all:  11%|█         | 11/100 [00:06<00:55,  1.60it/s, train_loss=0.522, train_acc=0.792, val_acc=0.796]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1]), array([6149])) real (array([0, 1]), array([1270, 4879]))\n",
      "graph level clf: all binary True test acc 0.7935 f1 0.8848 recall 1.0000 prec 0.7935 [[   0 1270]\n",
      " [   0 4879]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all:  21%|██        | 21/100 [00:12<00:49,  1.58it/s, train_loss=0.522, train_acc=0.792, val_acc=0.796]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1]), array([6149])) real (array([0, 1]), array([1270, 4879]))\n",
      "graph level clf: all binary True test acc 0.7935 f1 0.8848 recall 1.0000 prec 0.7935 [[   0 1270]\n",
      " [   0 4879]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all:  31%|███       | 31/100 [00:18<00:43,  1.57it/s, train_loss=0.522, train_acc=0.792, val_acc=0.796]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1]), array([6149])) real (array([0, 1]), array([1270, 4879]))\n",
      "graph level clf: all binary True test acc 0.7935 f1 0.8848 recall 1.0000 prec 0.7935 [[   0 1270]\n",
      " [   0 4879]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all:  41%|████      | 41/100 [00:24<00:37,  1.59it/s, train_loss=0.522, train_acc=0.792, val_acc=0.796]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1]), array([6149])) real (array([0, 1]), array([1270, 4879]))\n",
      "graph level clf: all binary True test acc 0.7935 f1 0.8848 recall 1.0000 prec 0.7935 [[   0 1270]\n",
      " [   0 4879]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all:  51%|█████     | 51/100 [00:29<00:30,  1.60it/s, train_loss=0.522, train_acc=0.792, val_acc=0.796]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1]), array([6149])) real (array([0, 1]), array([1270, 4879]))\n",
      "graph level clf: all binary True test acc 0.7935 f1 0.8848 recall 1.0000 prec 0.7935 [[   0 1270]\n",
      " [   0 4879]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all:  61%|██████    | 61/100 [00:35<00:24,  1.58it/s, train_loss=0.522, train_acc=0.792, val_acc=0.796]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1]), array([6149])) real (array([0, 1]), array([1270, 4879]))\n",
      "graph level clf: all binary True test acc 0.7935 f1 0.8848 recall 1.0000 prec 0.7935 [[   0 1270]\n",
      " [   0 4879]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all:  71%|███████   | 71/100 [00:41<00:18,  1.53it/s, train_loss=0.522, train_acc=0.792, val_acc=0.796]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1]), array([6149])) real (array([0, 1]), array([1270, 4879]))\n",
      "graph level clf: all binary True test acc 0.7935 f1 0.8848 recall 1.0000 prec 0.7935 [[   0 1270]\n",
      " [   0 4879]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all:  81%|████████  | 81/100 [00:47<00:11,  1.59it/s, train_loss=0.522, train_acc=0.792, val_acc=0.796]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1]), array([6149])) real (array([0, 1]), array([1270, 4879]))\n",
      "graph level clf: all binary True test acc 0.7935 f1 0.8848 recall 1.0000 prec 0.7935 [[   0 1270]\n",
      " [   0 4879]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all:  91%|█████████ | 91/100 [00:52<00:05,  1.59it/s, train_loss=0.522, train_acc=0.792, val_acc=0.796]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1]), array([6149])) real (array([0, 1]), array([1270, 4879]))\n",
      "graph level clf: all binary True test acc 0.7935 f1 0.8848 recall 1.0000 prec 0.7935 [[   0 1270]\n",
      " [   0 4879]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all: 100%|██████████| 100/100 [00:57<00:00,  1.73it/s, train_loss=0.522, train_acc=0.792, val_acc=0.796]\n"
     ]
    }
   ],
   "source": [
    "workflows = [\"all\", \"1000genome\", \n",
    "        \"nowcast-clustering-8\",\n",
    "        \"nowcast-clustering-16\",\n",
    "        \"wind-clustering-casa\",\n",
    "        \"wind-noclustering-casa\"]\n",
    "tasks = []\n",
    "task_loader = []\n",
    "for wf in workflows:\n",
    "    if wf == \"all\":\n",
    "        dataset = Merge_PSD_Dataset(node_level=False, binary_labels=True, anomaly_level=None).shuffle()\n",
    "    else:\n",
    "        dataset = PSD_Dataset(\"./\", wf,\n",
    "                              node_level=False,\n",
    "                              binary_labels=True,\n",
    "                              anomaly_level=None ).shuffle()\n",
    "        \n",
    "    temp_dataset = dataset\n",
    "    n_graphs = len(temp_dataset)\n",
    "    train_idx, val_idx = train_test_split( np.arange(n_graphs), train_size=0.6, random_state=0, shuffle=True)\n",
    "    # print(train_idx, test_idx, val_idx)\n",
    "    train_loader = DataLoader(temp_dataset[train_idx], batch_size=32)\n",
    "    val_loader = DataLoader(temp_dataset[val_idx], batch_size=32)\n",
    "    test_loader = DataLoader(dataset, batch_size=32)\n",
    "    task_loader.append( (train_loader, val_loader, test_loader))\n",
    "\n",
    "NUM_NODE_FEATURES = dataset.num_node_features\n",
    "NUM_OUT_FEATURES = dataset.num_classes\n",
    "print(NUM_NODE_FEATURES, NUM_OUT_FEATURES)\n",
    "\n",
    "''' Build GNN model '''\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "for (loaders, wfs) in zip(task_loader, workflows):\n",
    "    # default `log_dir` is \"runs\" - we'll be more specific here\n",
    "    writer = SummaryWriter('runs/'+wfs)\n",
    "\n",
    "    model = GNN(NUM_NODE_FEATURES,64, NUM_OUT_FEATURES).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-04)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "    (train_loader, val_loader, test_loader) = loaders\n",
    "    ts_start = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    pbar = tqdm(range(1000), desc=wfs)\n",
    "    best = 0\n",
    "    loss_array = []\n",
    "\n",
    "    for e in pbar:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss, outputs, model = train(model, train_loader)\n",
    "        train_acc, y_pred, _, _    = test(model, train_loader)\n",
    "        val_acc, _, _, _           = test(model, val_loader)\n",
    "        pbar.set_postfix({\"train_loss\": train_loss, \"train_acc\": train_acc, \"val_acc\": val_acc})\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "        loss_array.append(train_loss)\n",
    "        # ...log the running loss\n",
    "        writer.add_scalar('training loss', train_loss, e)\n",
    "        writer.add_scalar('training accuracy', train_acc, e)\n",
    "        writer.add_scalar('Validation accuracy', val_acc, e)\n",
    "\n",
    "        if e % 10 == 0:\n",
    "            # ## The resulting information\n",
    "            # actual_Data = model.dist.sample_n( 10000 )\n",
    "            # probs = model.dist.log_prob(actual_Data).exp().squeeze(1)\n",
    "            # args = np.argsort(actual_Data.squeeze(1).detach().cpu().numpy() )\n",
    "            # probs = probs[args]\n",
    "            # actual_Data = actual_Data[args]\n",
    "            # train_acc, y_pred, y_true, outputs = test(model, train_loader)\n",
    "            # plt.plot(actual_Data, probs)\n",
    "            # x, bins, p = plt.hist(outputs, density=True)\n",
    "            # for item in p:\n",
    "            #     item.set_height(item.get_height()/sum(x))\n",
    "            # # plt.xlim([0,1])\n",
    "            # # plt.ylim([0,1])\n",
    "            # plt.title(wfs)\n",
    "            # # plt.savefig('CL_Figures/'+wfs+'prob'+'.png', dpi = 500)\n",
    "            # plt.show()\n",
    "            # ## The final training metrics\n",
    "            # ys = []    \n",
    "            test_acc, y_pred, y_true, _ = test(model, test_loader)\n",
    "            print(np.unique(y_pred, return_counts=True), \"real\", np.unique(y_true, return_counts=True) )\n",
    "            conf_mat = confusion_matrix(y_true, y_pred)\n",
    "            prec_val = precision_score(y_true, y_pred)\n",
    "            f1_val = f1_score(y_true, y_pred)\n",
    "            recall_val = recall_score(y_true, y_pred)\n",
    "            print(\"graph level clf:\", wfs,\n",
    "                f\"binary True\",\n",
    "                f\"test acc {test_acc:.4f}\",\n",
    "                f\"f1 {f1_val:.4f}\",\n",
    "                f\"recall {recall_val:.4f}\",\n",
    "                f\"prec {prec_val:.4f}\", conf_mat, \"\\n\"\n",
    "                )\n",
    "    np.savetxt('CL_res/'+wfs+'upper_training.csv', np.array(loss_array), delimiter = ',')\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3b85852",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ff2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a57c047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 2\n"
     ]
    }
   ],
   "source": [
    "workflows = [\"1000genome\", \"nowcast-clustering-8\",\n",
    "        \"nowcast-clustering-16\",\n",
    "        \"wind-clustering-casa\",\n",
    "        \"wind-noclustering-casa\"]\n",
    "\n",
    "tt = Merge_PSD_Dataset(node_level=False, binary_labels=True, anomaly_level=None).shuffle()\n",
    "test_loader = DataLoader(tt, batch_size=32)\n",
    "tasks = []\n",
    "for wf in workflows:\n",
    "    dataset = PSD_Dataset(\"./\", wf,\n",
    "                            node_level=False,\n",
    "                            binary_labels=True,\n",
    "                            anomaly_level=None ).shuffle()\n",
    "    tasks.append(dataset)\n",
    "\n",
    "NUM_NODE_FEATURES = dataset.num_node_features\n",
    "NUM_OUT_FEATURES  = dataset.num_classes\n",
    "print(NUM_NODE_FEATURES, NUM_OUT_FEATURES)\n",
    "\n",
    "''' Build GNN model '''\n",
    "model = GNN(NUM_NODE_FEATURES, 64, NUM_OUT_FEATURES).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-03)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "070c8cc5",
   "metadata": {},
   "source": [
    "## The naive training for each workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47d2dd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one I am learning right now 1000genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000genome:   0%|          | 1/1000 [00:23<6:25:26, 23.15s/it, train_loss=0.346, train_acc=0.854, test_acc=0.793, f1 score=0.885]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: 1000genome binary True test acc 0.7935 f1 0.8848 recall 1.0000 prec 0.7935 [[   0 1270]\n",
      " [   0 4879]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000genome:  10%|█         | 101/1000 [02:57<22:57,  1.53s/it, train_loss=0.0274, train_acc=0.903, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: 1000genome binary True test acc 0.8037 f1 0.8886 recall 0.9869 prec 0.8082 [[ 127 1143]\n",
      " [  64 4815]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000genome:  20%|██        | 201/1000 [05:31<20:24,  1.53s/it, train_loss=0.0345, train_acc=0.902, test_acc=0.804, f1 score=0.889] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: 1000genome binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000genome:  30%|███       | 301/1000 [08:04<17:55,  1.54s/it, train_loss=0.0167, train_acc=0.902, test_acc=0.804, f1 score=0.889] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: 1000genome binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000genome:  40%|████      | 401/1000 [10:37<15:12,  1.52s/it, train_loss=0.0242, train_acc=0.902, test_acc=0.804, f1 score=0.889]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: 1000genome binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000genome:  50%|█████     | 501/1000 [13:10<12:41,  1.53s/it, train_loss=0.0274, train_acc=0.902, test_acc=0.804, f1 score=0.889] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: 1000genome binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000genome:  60%|██████    | 601/1000 [15:43<09:54,  1.49s/it, train_loss=0.0392, train_acc=0.902, test_acc=0.804, f1 score=0.889]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: 1000genome binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000genome:  70%|███████   | 701/1000 [18:11<07:21,  1.48s/it, train_loss=0.0307, train_acc=0.902, test_acc=0.804, f1 score=0.889]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: 1000genome binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000genome:  80%|████████  | 801/1000 [20:40<04:57,  1.49s/it, train_loss=0.00597, train_acc=0.902, test_acc=0.804, f1 score=0.889] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: 1000genome binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000genome:  90%|█████████ | 901/1000 [23:08<02:26,  1.48s/it, train_loss=0.0237, train_acc=0.902, test_acc=0.804, f1 score=0.889] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: 1000genome binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000genome: 100%|██████████| 1000/1000 [25:35<00:00,  1.54s/it, train_loss=0.0336, train_acc=0.902, test_acc=0.804, f1 score=0.889] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one I am learning right now nowcast-clustering-8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-8:   0%|          | 1/1000 [00:02<36:43,  2.21s/it, train_loss=1.58, train_acc=0.78, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-8 binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-8:  10%|█         | 101/1000 [02:25<21:20,  1.42s/it, train_loss=1.58, train_acc=0.78, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-8 binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-8:  20%|██        | 201/1000 [04:47<18:59,  1.43s/it, train_loss=1.54, train_acc=0.78, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-8 binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-8:  30%|███       | 301/1000 [07:10<16:31,  1.42s/it, train_loss=1.55, train_acc=0.78, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-8 binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-8:  40%|████      | 401/1000 [09:32<14:11,  1.42s/it, train_loss=1.52, train_acc=0.78, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-8 binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-8:  50%|█████     | 501/1000 [11:55<11:47,  1.42s/it, train_loss=1.53, train_acc=0.78, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-8 binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-8:  60%|██████    | 601/1000 [14:17<09:24,  1.42s/it, train_loss=1.52, train_acc=0.78, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-8 binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-8:  70%|███████   | 701/1000 [16:40<07:07,  1.43s/it, train_loss=1.55, train_acc=0.78, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-8 binary True test acc 0.8037 f1 0.8886 recall 0.9871 prec 0.8081 [[ 126 1144]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-8:  80%|████████  | 801/1000 [19:02<04:41,  1.42s/it, train_loss=1.53, train_acc=0.78, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-8 binary True test acc 0.8039 f1 0.8887 recall 0.9871 prec 0.8082 [[ 127 1143]\n",
      " [  63 4816]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-8:  90%|█████████ | 901/1000 [21:24<02:22,  1.44s/it, train_loss=1.57, train_acc=0.78, test_acc=0.804, f1 score=0.888]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-8 binary True test acc 0.8035 f1 0.8885 recall 0.9865 prec 0.8082 [[ 128 1142]\n",
      " [  66 4813]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-8: 100%|██████████| 1000/1000 [23:51<00:00,  1.43s/it, train_loss=1.55, train_acc=0.78, test_acc=0.803, f1 score=0.888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one I am learning right now nowcast-clustering-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-16:   0%|          | 1/1000 [00:01<33:04,  1.99s/it, train_loss=1.56, train_acc=0.778, test_acc=0.803, f1 score=0.888]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-16 binary True test acc 0.8034 f1 0.8884 recall 0.9863 prec 0.8082 [[ 128 1142]\n",
      " [  67 4812]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-16:  10%|█         | 101/1000 [02:29<22:11,  1.48s/it, train_loss=1.54, train_acc=0.778, test_acc=0.803, f1 score=0.888]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-16 binary True test acc 0.8034 f1 0.8884 recall 0.9863 prec 0.8082 [[ 128 1142]\n",
      " [  67 4812]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-16:  20%|██        | 201/1000 [04:56<19:34,  1.47s/it, train_loss=1.57, train_acc=0.778, test_acc=0.804, f1 score=0.888]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-16 binary True test acc 0.8035 f1 0.8885 recall 0.9863 prec 0.8083 [[ 129 1141]\n",
      " [  67 4812]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-16:  30%|███       | 301/1000 [07:23<17:04,  1.47s/it, train_loss=1.56, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-16 binary True test acc 0.8037 f1 0.8886 recall 0.9863 prec 0.8085 [[ 130 1140]\n",
      " [  67 4812]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-16:  40%|████      | 401/1000 [09:50<14:30,  1.45s/it, train_loss=1.55, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-16 binary True test acc 0.8039 f1 0.8886 recall 0.9863 prec 0.8086 [[ 131 1139]\n",
      " [  67 4812]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-16:  50%|█████     | 501/1000 [12:12<11:38,  1.40s/it, train_loss=1.56, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-16 binary True test acc 0.8039 f1 0.8886 recall 0.9863 prec 0.8086 [[ 131 1139]\n",
      " [  67 4812]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-16:  60%|██████    | 601/1000 [14:35<09:32,  1.43s/it, train_loss=1.53, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-16 binary True test acc 0.8039 f1 0.8886 recall 0.9863 prec 0.8086 [[ 131 1139]\n",
      " [  67 4812]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-16:  70%|███████   | 701/1000 [16:57<07:05,  1.42s/it, train_loss=1.56, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-16 binary True test acc 0.8039 f1 0.8886 recall 0.9863 prec 0.8086 [[ 131 1139]\n",
      " [  67 4812]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-16:  80%|████████  | 801/1000 [19:20<04:45,  1.43s/it, train_loss=1.58, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-16 binary True test acc 0.8042 f1 0.8888 recall 0.9863 prec 0.8089 [[ 133 1137]\n",
      " [  67 4812]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-16:  90%|█████████ | 901/1000 [21:43<02:21,  1.43s/it, train_loss=1.58, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: nowcast-clustering-16 binary True test acc 0.8042 f1 0.8888 recall 0.9861 prec 0.8090 [[ 134 1136]\n",
      " [  68 4811]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nowcast-clustering-16: 100%|██████████| 1000/1000 [24:04<00:00,  1.44s/it, train_loss=1.56, train_acc=0.778, test_acc=0.805, f1 score=0.889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one I am learning right now wind-clustering-casa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-clustering-casa:   0%|          | 1/1000 [00:02<33:33,  2.02s/it, train_loss=1.55, train_acc=0.778, test_acc=0.805, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-clustering-casa binary True test acc 0.8047 f1 0.8890 recall 0.9861 prec 0.8094 [[ 137 1133]\n",
      " [  68 4811]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-clustering-casa:  10%|█         | 101/1000 [02:24<21:11,  1.41s/it, train_loss=1.53, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-clustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9857 prec 0.8093 [[ 137 1133]\n",
      " [  70 4809]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-clustering-casa:  20%|██        | 201/1000 [04:46<18:49,  1.41s/it, train_loss=1.55, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-clustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9857 prec 0.8093 [[ 137 1133]\n",
      " [  70 4809]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-clustering-casa:  30%|███       | 301/1000 [07:08<16:35,  1.42s/it, train_loss=1.56, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-clustering-casa binary True test acc 0.8042 f1 0.8887 recall 0.9854 prec 0.8093 [[ 137 1133]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-clustering-casa:  40%|████      | 401/1000 [09:30<14:05,  1.41s/it, train_loss=1.56, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-clustering-casa binary True test acc 0.8042 f1 0.8887 recall 0.9854 prec 0.8093 [[ 137 1133]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-clustering-casa:  50%|█████     | 501/1000 [11:53<11:49,  1.42s/it, train_loss=1.54, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-clustering-casa binary True test acc 0.8042 f1 0.8887 recall 0.9854 prec 0.8093 [[ 137 1133]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-clustering-casa:  60%|██████    | 601/1000 [14:15<09:30,  1.43s/it, train_loss=1.58, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-clustering-casa binary True test acc 0.8042 f1 0.8887 recall 0.9854 prec 0.8093 [[ 137 1133]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-clustering-casa:  70%|███████   | 701/1000 [16:37<07:04,  1.42s/it, train_loss=1.54, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-clustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9854 prec 0.8094 [[ 138 1132]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-clustering-casa:  80%|████████  | 801/1000 [18:59<04:42,  1.42s/it, train_loss=1.54, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-clustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9854 prec 0.8094 [[ 138 1132]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-clustering-casa:  90%|█████████ | 901/1000 [21:21<02:22,  1.44s/it, train_loss=1.56, train_acc=0.778, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-clustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9854 prec 0.8094 [[ 138 1132]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-clustering-casa: 100%|██████████| 1000/1000 [23:42<00:00,  1.42s/it, train_loss=1.56, train_acc=0.778, test_acc=0.804, f1 score=0.889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one I am learning right now wind-noclustering-casa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-noclustering-casa:   0%|          | 1/1000 [00:02<35:13,  2.12s/it, train_loss=1.39, train_acc=0.773, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-noclustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9854 prec 0.8094 [[ 138 1132]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-noclustering-casa:  10%|█         | 101/1000 [02:23<21:20,  1.42s/it, train_loss=1.4, train_acc=0.773, test_acc=0.804, f1 score=0.889] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-noclustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9854 prec 0.8094 [[ 138 1132]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-noclustering-casa:  20%|██        | 201/1000 [04:44<18:46,  1.41s/it, train_loss=1.41, train_acc=0.773, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-noclustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9854 prec 0.8094 [[ 138 1132]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-noclustering-casa:  30%|███       | 301/1000 [07:06<16:26,  1.41s/it, train_loss=1.41, train_acc=0.773, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-noclustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9854 prec 0.8094 [[ 138 1132]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-noclustering-casa:  40%|████      | 401/1000 [09:27<13:56,  1.40s/it, train_loss=1.39, train_acc=0.773, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-noclustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9854 prec 0.8094 [[ 138 1132]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-noclustering-casa:  50%|█████     | 501/1000 [11:49<11:40,  1.40s/it, train_loss=1.4, train_acc=0.773, test_acc=0.804, f1 score=0.889] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-noclustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9854 prec 0.8094 [[ 138 1132]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-noclustering-casa:  60%|██████    | 601/1000 [14:10<09:24,  1.42s/it, train_loss=1.41, train_acc=0.773, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-noclustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9854 prec 0.8094 [[ 138 1132]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-noclustering-casa:  70%|███████   | 701/1000 [16:31<07:00,  1.41s/it, train_loss=1.42, train_acc=0.773, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-noclustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9854 prec 0.8094 [[ 138 1132]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-noclustering-casa:  80%|████████  | 801/1000 [18:53<04:40,  1.41s/it, train_loss=1.37, train_acc=0.773, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-noclustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9854 prec 0.8094 [[ 138 1132]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-noclustering-casa:  90%|█████████ | 901/1000 [21:14<02:19,  1.41s/it, train_loss=1.39, train_acc=0.773, test_acc=0.804, f1 score=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph level clf: wind-noclustering-casa binary True test acc 0.8044 f1 0.8888 recall 0.9854 prec 0.8094 [[ 138 1132]\n",
      " [  71 4808]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wind-noclustering-casa: 100%|██████████| 1000/1000 [23:34<00:00,  1.41s/it, train_loss=1.42, train_acc=0.773, test_acc=0.804, f1 score=0.889]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "acc_arr = []\n",
    "f1_arr = []\n",
    "precision_arr = []\n",
    "recall_arr = [] \n",
    "loss_array = []\n",
    "for (wfs, dataset) in zip(workflows, tasks):\n",
    "    print(\"The one I am learning right now\", wfs)\n",
    "    n_graphs = len(dataset)\n",
    "    train_idx, test_idx = train_test_split( np.arange(n_graphs),\\\n",
    "                        train_size=0.6,\\\n",
    "                        random_state=0,\\\n",
    "                        shuffle=True)\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(dataset[train_idx], batch_size=32)\n",
    "    writer = SummaryWriter('runs/'+wfs)\n",
    "    ts_start = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    pbar = tqdm(range(1000), desc=wfs)\n",
    "    best = 0\n",
    "    for e in pbar:\n",
    "        train_loss, outputs, model   = train(model, train_loader)\n",
    "        train_acc, y_pred, _, _= test(model, train_loader)\n",
    "        test_acc, y_pred, y_true, _ = test(model, test_loader)\n",
    "\n",
    "        conf_mat = confusion_matrix(y_true, y_pred)\n",
    "        prec_val = precision_score(y_true, y_pred)\n",
    "        f1_val = f1_score(y_true, y_pred)\n",
    "        recall_val = recall_score(y_true, y_pred)\n",
    "        \n",
    "        pbar.set_postfix({\"train_loss\": train_loss,\\\n",
    "                        \"train_acc\": train_acc,\\\n",
    "                        \"test_acc\": test_acc,\\\n",
    "                        \"f1 score\": f1_val})\n",
    "        \n",
    "        scheduler.step(train_loss)\n",
    "        \n",
    "        # ...log the running loss\n",
    "        writer.add_scalar('training loss', train_loss, e)\n",
    "        writer.add_scalar('training accuracy', train_acc, e)\n",
    "        writer.add_scalar('Test accuracy', test_acc, e)\n",
    "\n",
    "\n",
    "        loss_array.append(train_loss)\n",
    "        acc_arr.append(test_acc)\n",
    "        f1_arr.append(f1_val)\n",
    "        precision_arr.append(prec_val)\n",
    "        recall_arr.append(recall_val)\n",
    "        if e %100 == 0:\n",
    "            print(\"graph level clf:\",\n",
    "                wfs,\n",
    "                f\"binary True\",\n",
    "                f\"test acc {test_acc:.4f}\",\n",
    "                f\"f1 {f1_val:.4f}\",\n",
    "                f\"recall {recall_val:.4f}\",\n",
    "                f\"prec {prec_val:.4f}\", conf_mat, \"\\n\"\n",
    "                )\n",
    "\n",
    "np.savetxt('CL_res/Naive_training_loss.csv', np.array(loss_array), delimiter = ',')\n",
    "np.savetxt('CL_res/Naive_acc.csv', np.array(acc_arr), delimiter = ',')\n",
    "np.savetxt('CL_res/Naive_precision.csv', np.array(precision_arr), delimiter = ',')\n",
    "np.savetxt('CL_res/Naive_recall.csv', np.array(recall_arr), delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a33e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d70198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58afec2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0f85fbc",
   "metadata": {},
   "source": [
    "The CL function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f501bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ecf130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79cc70c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9a428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd39cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26e11b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6e233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc0d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db413b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9750a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6022c081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a3c973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba508d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741040a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6b47e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3edd04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce3bf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e874c84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929b92c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1201f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbdb347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
